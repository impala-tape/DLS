{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C886eqWV6-o"
      },
      "source": [
        "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
        "\n",
        "<h1 style=\"text-align: center;\"><b>Домашнее задание. Решение конкурса на kaggle</b></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYyCvoyQV6-p"
      },
      "source": [
        "\n",
        "\n",
        "Это домашнее задание посвящено полноценному решению задачи машинного обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlB-owfaEEYs"
      },
      "source": [
        "Есть две части этого домашнего задания:\n",
        "\n",
        "### Отправить ваши предсказания в Stepik.\n",
        "За прохождение определенных порогов будут начисляться баллы. Эта часть оценивается из 5 баллов.\n",
        "\n",
        "1) $1.00 \\geqslant score \\geqslant 0.84$ --- 5 баллов\n",
        "\n",
        "2) $0.84 > score \\geqslant 0.77$ --- 4 балла\n",
        "\n",
        "3) $0.77 > score \\geqslant 0.70$ --- 3 балла\n",
        "\n",
        "4) $0.70 > score \\geqslant 0.65$ --- 2 балла\n",
        "\n",
        "5) $0.65 > score \\geqslant 0.6$ --- 1 балл\n",
        "\n",
        "6) $0.60 > score$ --- 0 баллов\n",
        "\n",
        "Для этого мы предварительно разделили данные в задании на две части.\n",
        "* `train.csv`. На этом наборе данных вам необходимо создать и обучить модель. Подробное описание файла есть в ноутбуке.\n",
        "* `test.csv`. В каждой строчке файла `test.csv` указаны признаки тестовых объектов. Предсказания для этого набора необходимо записать в файл submission.csv и сдать в соответствующий шаг на Stepik. Количество попыток ограничено 100 штук.\n",
        "\n",
        "Отправлять в Stepik вы будете файл с ответами `my_submission.csv`. В этом файле вам необходимо для каждого объекта из датасета предсказать вероятность класса 1. Мы подготовили для вас файл с примером посылки `submission.csv`. Ваш файл должен быть оформлен таким же образом. В ноутбуке есть пример оформления файла посылки. Для отправки файла с предсказаниями на Stepik есть отдельный шаг.\n",
        "\n",
        "### Сделать полноценный отчет о вашей работе.\n",
        "Опишите, как вы обработали данные, какие модели попробовали и какие результаты получились (максимум 10 баллов). За каждую выполненную часть будет начислено определенное количество баллов. В этом пункте вам необходимо отправить файл в формате .ipynb на Stepik --- для этого в домашнем задании есть отдельный шаг. Этот пункт оценивается из 10 баллов.\n",
        "\n",
        "**Вторая часть будет проверяться в формате peer-review. Т.е. вашу посылку на Stepik будут проверять 3 других студента, и медианное значение их оценок будет выставлено. Чтобы получить баллы, вам также нужно будет проверить трех других учеников. Это станет доступно после того, как вы сдадите задание сами.**\n",
        "\n",
        "### Контест на Kaggle\n",
        "Для вашего удобства мы подготовили [контест на Kaggle](https://www.kaggle.com/c/advanced-dls-spring-2021/). Тестирующая система на Kaggle выдает те же баллы, что и Stepik. Мы рекомендуем в качестве основной тестирующей системы использовать именно Kaggle, а затем сдать лучшую посылку на Stepik. Так вы привыкните работать с Kaggle.\n",
        "\n",
        "Проблема для российских пользователей Kaggle заключается в том, что подтверждение аккаунта по номеру телефона работает с перебоями или не работает вообще. Без подтвержденного номера телефона вы не сможете совершать посылки в kaggle. Если у вас возникла такая проблема, мы советуем следующие шаги:\n",
        "* Попробовать зарегистрировать аккаунт с аутентификацией через gmail. В таком случае, аккаунт должен работать без подтверждения номера телефона.\n",
        "* Если у вас есть не российский номер, используйте его для верификации аккаунта.\n",
        "* Если на номер телефона не приходит смс для верификации аккаунта, обратитесь в службу поддержки kaggle. Они с переменным успехом умеют подтверждать аккаунты вручную.\n",
        "* Если все же подтвердить аккаунт и получить доступ к сдаче заданий не удалось, используйте только сдачу в Stepik.\n",
        "\n",
        "### Несколько замечаний по выполнению работы\n",
        "* Во всех пунктах указания это минимальный набор вещей, которые стоит сделать. Если вы можете сделать какой-то шаг лучше или добавить что-то свое --- дерзайте!\n",
        "* Пожалуйста, перед сдачей ноутбука убедитесь, что работа чистая и понятная. Это значительно облегчит проверку и повысит ваши ожидаемые баллы.\n",
        "* Если у вас будут проблемы с решением или хочется совета, то пишите в наш чат в телеграме.\n",
        "\n",
        "\n",
        "Данные: [train.csv](https://drive.google.com/file/d/1ERwQ5odiK1Zvi1LtjpkzCMUswYsAX8_K/view?usp=share_link),\n",
        "[test.csv](https://drive.google.com/file/d/1fGw_-RFwvn_LEdt91Jq-7A-wzG6mmH8r/view?usp=share_link), [submission.csv](https://drive.google.com/file/d/199Mt4OYZNaelT83U-HGDsEYs2YcUGQ6y/view?usp=share_link).\n",
        "\n",
        "Если ссылки на данные не работают, их можно скачать [на Kaggle](https://www.kaggle.com/competitions/advanced-dls-spring-2021/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu_JvqcBEN8Y"
      },
      "source": [
        "# Как проверять?\n",
        "\n",
        "Ставьте полный балл, если выполнены все рекомендации или сделано что-то более интересное и сложное. За каждый отсустствующий пункт из рекомендации снижайте 1 балл.\n",
        "\n",
        "**Если решение верное, но не удовлетворяет вашим эстетическим предпочтениям, за это баллы снижать не нужно.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ninJ63mJEEYt"
      },
      "source": [
        "# Метрика\n",
        "\n",
        "Перед решением любой задачи важно понимать, как будет оцениваться ваше решение. В данном случае мы используем стандартную для задачи классификации метрику ROC-AUC. Ее можно вычислить, используя только предсказанные вероятности и истинные классы без конкретного порога классификации + она работает даже если классы в данных сильно несбалансированны (примеров одного класса в десятки раз больше примеров длугого). Именно поэтому она очень удобна для соревнований.\n",
        "\n",
        "Посчитать ее легко:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQIrka7yEEYu",
        "outputId": "b8554c71-63db-42a6-b703-7f81b60775f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.8333333333333333)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_true = [\n",
        "    0,\n",
        "    1,\n",
        "    1,\n",
        "    0,\n",
        "    1\n",
        "]\n",
        "\n",
        "y_predictions = [\n",
        "    0.1,\n",
        "    0.9,\n",
        "    0.4,\n",
        "    0.6,\n",
        "    0.61\n",
        "]\n",
        "\n",
        "roc_auc_score(y_true, y_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrDNNkNTEEYz"
      },
      "source": [
        "# Первая часть. Исследование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "lzLqEeZKEEYz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOlxdURSEEY3"
      },
      "source": [
        "## Загрузка данных (2 балла)\n",
        "\n",
        "1) Посмотрите на случайные строчки.\n",
        "\n",
        "2) Посмотрите, есть ли в датасете незаполненные значения (nan'ы) с помощью data.isna() или data.info() и, если нужно, замените их на что-то. Будет хорошо, если вы построите табличку с количеством nan в каждой колонке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XULA1f3ch6RL",
        "outputId": "711ae122-59fd-41e9-fdc7-5dd4add70aef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ERwQ5odiK1Zvi1LtjpkzCMUswYsAX8_K\n",
            "To: c:\\Users\\Mishele Dolmin\\CODE\\DLS\\8\\train.csv\n",
            "\n",
            "  0%|          | 0.00/664k [00:00<?, ?B/s]\n",
            " 79%|███████▉  | 524k/664k [00:00<00:00, 940kB/s]\n",
            "100%|██████████| 664k/664k [00:00<00:00, 1.10MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fGw_-RFwvn_LEdt91Jq-7A-wzG6mmH8r\n",
            "To: c:\\Users\\Mishele Dolmin\\CODE\\DLS\\8\\test.csv\n",
            "\n",
            "  0%|          | 0.00/218k [00:00<?, ?B/s]\n",
            "100%|██████████| 218k/218k [00:00<00:00, 577kB/s]\n",
            "100%|██████████| 218k/218k [00:00<00:00, 576kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=199Mt4OYZNaelT83U-HGDsEYs2YcUGQ6y\n",
            "To: c:\\Users\\Mishele Dolmin\\CODE\\DLS\\8\\submission.csv\n",
            "\n",
            "  0%|          | 0.00/14.7k [00:00<?, ?B/s]\n",
            "100%|██████████| 14.7k/14.7k [00:00<00:00, 1.09MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1ERwQ5odiK1Zvi1LtjpkzCMUswYsAX8_K  \n",
        "# train.csv\n",
        "!gdown 1fGw_-RFwvn_LEdt91Jq-7A-wzG6mmH8r  \n",
        "# test.csv\n",
        "!gdown 199Mt4OYZNaelT83U-HGDsEYs2YcUGQ6y  \n",
        "# submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "pw-Brue9EEY3"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('./train.csv')\n",
        "test = pd.read_csv('./test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "KgnkkF5bEEY9"
      },
      "outputs": [],
      "source": [
        "# # Для вашего удобства списки с именами разных колонок\n",
        "\n",
        "# # Числовые признаки\n",
        "# num_cols = [\n",
        "#     'ClientPeriod',\n",
        "#     'MonthlySpending',\n",
        "#     'TotalSpent'\n",
        "# ]\n",
        "\n",
        "# # Категориальные признаки\n",
        "# cat_cols = [\n",
        "#     'Sex',\n",
        "#     'IsSeniorCitizen',\n",
        "#     'HasPartner',\n",
        "#     'HasChild',\n",
        "#     'HasPhoneService',\n",
        "#     'HasMultiplePhoneNumbers',\n",
        "#     'HasInternetService',\n",
        "#     'HasOnlineSecurityService',\n",
        "#     'HasOnlineBackup',\n",
        "#     'HasDeviceProtection',\n",
        "#     'HasTechSupportAccess',\n",
        "#     'HasOnlineTV',\n",
        "#     'HasMovieSubscription',\n",
        "#     'HasContractPhone',\n",
        "#     'IsBillingPaperless',\n",
        "#     'PaymentMethod'\n",
        "# ]\n",
        "\n",
        "# feature_cols = num_cols + cat_cols\n",
        "# target_col = 'Churn'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте взлянем на 20 случайных строк датасета, чтобы понять, что там вообще содержится\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.sample(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим на типизацию данных в разных колонках"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ClientPeriod int64 int64\n",
            "MonthlySpending float64 float64\n",
            "TotalSpent object object\n",
            "Sex object object\n",
            "IsSeniorCitizen int64 int64\n",
            "HasPartner object object\n",
            "HasChild object object\n",
            "HasPhoneService object object\n",
            "HasMultiplePhoneNumbers object object\n",
            "HasInternetService object object\n",
            "HasOnlineSecurityService object object\n",
            "HasOnlineBackup object object\n",
            "HasDeviceProtection object object\n",
            "HasTechSupportAccess object object\n",
            "HasOnlineTV object object\n",
            "HasMovieSubscription object object\n",
            "HasContractPhone object object\n",
            "IsBillingPaperless object object\n",
            "PaymentMethod object object\n"
          ]
        }
      ],
      "source": [
        "for i in feature_cols:\n",
        "    print(i, data[i].dtype, test[i].dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TotalSpent почему-то не float. Давайте это исправим!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float64\n"
          ]
        }
      ],
      "source": [
        "# В train\n",
        "data['TotalSpent'] = pd.to_numeric(data['TotalSpent'], errors='coerce')\n",
        "print(data['TotalSpent'].dtype) #Должно быть float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float64\n"
          ]
        }
      ],
      "source": [
        "# В тестовой выборке\n",
        "test['TotalSpent'] = pd.to_numeric(test['TotalSpent'], errors='coerce')\n",
        "print(test['TotalSpent'].dtype) #Должно быть float64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Давайте проверим данные на Nan'ы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMbgY4rJpCbo",
        "outputId": "104a2a44-c558-4b82-d64b-f55c8861b747"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClientPeriod                0\n",
              "MonthlySpending             0\n",
              "TotalSpent                  9\n",
              "Sex                         0\n",
              "IsSeniorCitizen             0\n",
              "HasPartner                  0\n",
              "HasChild                    0\n",
              "HasPhoneService             0\n",
              "HasMultiplePhoneNumbers     0\n",
              "HasInternetService          0\n",
              "HasOnlineSecurityService    0\n",
              "HasOnlineBackup             0\n",
              "HasDeviceProtection         0\n",
              "HasTechSupportAccess        0\n",
              "HasOnlineTV                 0\n",
              "HasMovieSubscription        0\n",
              "HasContractPhone            0\n",
              "IsBillingPaperless          0\n",
              "PaymentMethod               0\n",
              "Churn                       0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClientPeriod                0\n",
              "MonthlySpending             0\n",
              "TotalSpent                  2\n",
              "Sex                         0\n",
              "IsSeniorCitizen             0\n",
              "HasPartner                  0\n",
              "HasChild                    0\n",
              "HasPhoneService             0\n",
              "HasMultiplePhoneNumbers     0\n",
              "HasInternetService          0\n",
              "HasOnlineSecurityService    0\n",
              "HasOnlineBackup             0\n",
              "HasDeviceProtection         0\n",
              "HasTechSupportAccess        0\n",
              "HasOnlineTV                 0\n",
              "HasMovieSubscription        0\n",
              "HasContractPhone            0\n",
              "IsBillingPaperless          0\n",
              "PaymentMethod               0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "177\n",
            "767\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(test['TotalSpent'].isna())):\n",
        "    if test['TotalSpent'].isna()[i] == True:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В строках, где сейчас None, вместо числа в исходных данных была строка с пробелом. Предположим, что это значит, что значение TotalSpent в этом случае равно 0, изменим данные соответствующим образом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['TotalSpent'] = data['TotalSpent'].fillna(float(0))\n",
        "test['TotalSpent'] = test['TotalSpent'].fillna(float(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK370bPCEEZD"
      },
      "source": [
        "## Анализ данных (3 балла)\n",
        "\n",
        "1) Для численных призанков постройте гистограмму (*plt.hist(...)*) или boxplot (*plt.boxplot(...)*). Для категориальных посчитайте количество каждого значения для каждого признака. Для каждой колонки надо сделать *data.value_counts()* и построить bar диаграммы *plt.bar(...)* или круговые диаграммы *plt.pie(...)* (хорошо, елси вы сможете это сделать на одном гарфике с помощью *plt.subplots(...)*).\n",
        "\n",
        "2) Посмотрите на распределение целевой переменной и скажите, являются ли классы несбалансированными.\n",
        "\n",
        "3) (Если будет желание) Поиграйте с разными библиотеками для визуализации - *sns*, *pandas_visual_analysis*, etc.\n",
        "\n",
        "Второй пункт очень важен, потому что существуют задачи классификации с несбалансированными классами. Например, это может значить, что в датасете намного больше примеров 0 класса. В таких случаях нужно 1) не использовать accuracy как метрику 2) использовать методы борьбы с imbalanced dataset (обычно если датасет сильно несбалансирован, т.е. класса 1 в 20 раз меньше класса 0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "NZkbgFJZEEZE",
        "outputId": "5144e3fe-c7b7-4ff2-a9c7-7423ae74e189"
      },
      "outputs": [],
      "source": [
        "# Создаем подграфики\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Отрисовываем boxplot для каждого столбца\n",
        "sns.boxplot(y=data['ClientPeriod'], ax=axes[0], color='skyblue', flierprops=dict(marker='o', markersize=8, markerfacecolor='red'))\n",
        "axes[0].set_title('ClientPeriod')\n",
        "axes[0].set_ylabel('Значения')\n",
        "\n",
        "sns.boxplot(y=data['MonthlySpending'], ax=axes[1], color='lightgreen', flierprops=dict(marker='o', markersize=8, markerfacecolor='red'))\n",
        "axes[1].set_title('MonthlySpending')\n",
        "axes[1].set_ylabel('Значения')\n",
        "\n",
        "sns.boxplot(y=data['TotalSpent'], ax=axes[2], color='salmon',flierprops=dict(marker='o', markersize=8, markerfacecolor='red'))\n",
        "axes[2].set_title('TotalSpent')\n",
        "axes[2].set_ylabel('Значения')\n",
        "\n",
        "# # Настраиваем шкалу Y на последнем графике (TotalSpent)\n",
        "# max_value = data['TotalSpent'].max()  # Максимальное значение в данных\n",
        "# yticks = np.arange(0, int(max_value) + 500, 500)  # Шкала с шагом 500\n",
        "# axes[2].set_yticks(yticks)  # Устанавливаем шкалу\n",
        "\n",
        "# Общий заголовок\n",
        "plt.suptitle('Boxplot для числовых признаков', fontsize=16)\n",
        "\n",
        "# Показываем графики\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKUgCD07qXo3"
      },
      "source": [
        "Выбросов не обнаружено"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "sew2QlT0qhSy",
        "outputId": "3ee7a757-c2a1-4666-e319-8fdf28fe1dbe"
      },
      "outputs": [],
      "source": [
        "churn_counts = data['Churn'].value_counts()\n",
        "\n",
        "# Создаем подписи для диаграммы\n",
        "labels = ['Не ушли (0)', 'Ушли (1)']\n",
        "sizes = churn_counts.values  # Количество 0 и 1\n",
        "colors = ['lightgreen', 'lightcoral']  # Цвета для секторов\n",
        "explode = (0.1, 0)  # \"Выделяем\" первый сектор (0)\n",
        "\n",
        "# Строим круговую диаграмму\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Распределение Churn (0 и 1)')\n",
        "plt.axis('equal')  # Чтобы диаграмма была круглой\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Датасет имеет не критический дисбаланс, но нам не стоит использовать accuracy как метрику."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создание фигуры с подграфиками\n",
        "num_cols = 4  # Количество графиков в ряду\n",
        "num_rows = (len(cat_cols) + num_cols - 1) // num_cols  # Количество рядов\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, num_rows * 5))\n",
        "fig.suptitle('Pie-графики для категориальных признаков', fontsize=24, y=1.02)\n",
        "\n",
        "# Построение pie-графиков для каждого столбца\n",
        "for i, col in enumerate(cat_cols):\n",
        "    # Подсчет значений в столбце\n",
        "    value_counts = data[col].value_counts()\n",
        "    \n",
        "    # Определение позиции подграфика\n",
        "    ax = axes[i // num_cols, i % num_cols]\n",
        "    \n",
        "    # Построение pie-графика\n",
        "    ax.pie(\n",
        "        value_counts,\n",
        "        labels=value_counts.index,\n",
        "        autopct='%1.1f%%',  # Процент с одним знаком после запятой\n",
        "        startangle=90,\n",
        "        colors=plt.cm.Paired.colors,\n",
        "        wedgeprops={'edgecolor': 'black', 'linewidth': 1},\n",
        "        textprops={'fontsize': 10}  # Размер шрифта для подписей\n",
        "    )\n",
        "    ax.set_title(f'Распределение для {col}', fontsize=14)\n",
        "\n",
        "# Удаление пустых подграфиков, если количество столбцов не кратно 4\n",
        "for i in range(len(cat_cols), num_rows * num_cols):\n",
        "    fig.delaxes(axes.flatten()[i])\n",
        "\n",
        "# Настройка отступов\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg60u3QDEEZH"
      },
      "source": [
        "(Дополнительно) Если вы нашли какие-то ошибки в данных или выбросы, то можете их убрать. Тут можно поэксперементировать с обработкой данных как угодно, но не за баллы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "fwfksF1gEEZI"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DviiJd8REEZK"
      },
      "source": [
        "## Применение линейных моделей (3 балла)\n",
        "\n",
        "1) Обработайте данные для того, чтобы к ним можно было применить LogisticRegression. Т.е. отнормируйте числовые признаки, а категориальные закодируйте с помощью one-hot-encoding'а.\n",
        "\n",
        "2) С помощью кроссвалидации или разделения на train/valid выборку протестируйте разные значения гиперпараметра C и выберите лучший (можно тестировать С=100, 10, 1, 0.1, 0.01, 0.001) по метрике ROC-AUC.\n",
        "\n",
        "Если вы разделяете на train/valid, то используйте LogisticRegressionCV. Он сам при вызове .fit() подберет параметр С. (не забудьте передать scroing='roc_auc', чтобы при кроссвалидации сравнивались значения этой метрики, и refit=True, чтобы при потом модель обучилась на всем датасете с лучшим параметром C).\n",
        "\n",
        "\n",
        "(более сложный вариант) Если вы будете использовать кроссвалидацию, то преобразования данных и LogisticRegression нужно соединить в один Pipeline с помощью make_pipeline, как это делалось во втором семинаре. Потом pipeline надо передать в GridSearchCV. Для one-hot-encoding'a можно испльзовать комбинацию LabelEncoder + OneHotEncoder (сначала превращаем строчки в числа, а потом числа првращаем в one-hot вектора.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Заведем отдельный датасет, в котором и подготовим данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "l_data = data.copy()\n",
        "l_test = test.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OHE для l_data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OHE for l_data\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#Initialize OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Apply one-hot encoding to the categorical columns\n",
        "one_hot_encoded = encoder.fit_transform(data[cat_cols])\n",
        "\n",
        "#Create a DataFrame with the one-hot encoded columns\n",
        "#We use get_feature_names_out() to get the column names for the encoded data\n",
        "ohe_data = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(cat_cols), index=data.index)\n",
        "ohe_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OHE для l_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OHE for l_data\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#Initialize OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Apply one-hot encoding to the categorical columns\n",
        "one_hot_encoded = encoder.fit_transform(test[cat_cols])\n",
        "\n",
        "#Create a DataFrame with the one-hot encoded columns\n",
        "#We use get_feature_names_out() to get the column names for the encoded data\n",
        "ohe_test = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(cat_cols), index=test.index)\n",
        "ohe_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l_data = pd.concat([l_data, ohe_data], axis=1)\n",
        "l_data = l_data.drop(cat_cols, axis=1)\n",
        "l_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l_test = pd.concat([l_test, ohe_test], axis=1)\n",
        "l_test = l_test.drop(cat_cols, axis=1)\n",
        "l_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Количество столбцов совпадает, значит в test есть все то же множество значений, что и в train, не нужно добавлять колонки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Делим train dataset на валидационную и тестовую выборку:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = l_data.drop(columns=['Churn']).values\n",
        "y = l_data['Churn'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Разделение на train/valid/test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Mishele Dolmin\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Нормализация данных\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_subm_scaled = scaler.transform(l_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.91630938,  1.62387377,  1.76084447, -0.99864847,  0.99864847,\n",
              "       -2.27873426,  2.27873426, -1.01608829,  1.01608829,  0.66728535,\n",
              "       -0.66728535, -0.34390378,  0.34390378, -0.94037319, -0.34390378,\n",
              "        1.16330485, -0.72641995,  1.12671668, -0.52172355,  1.01224702,\n",
              "       -0.52172355, -0.64240663, -0.90125185, -0.52172355,  1.39998856,\n",
              "       -0.87976833, -0.52172355,  1.36354027, -0.98310191, -0.52172355,\n",
              "        1.54753277, -0.82443378, -0.52172355,  1.27357207, -0.81153638,\n",
              "       -0.52172355,  1.2533682 , -1.11810204, -0.49856261,  1.75387427,\n",
              "       -0.823046  ,  0.823046  , -0.5376352 , -0.51794554,  1.40168303,\n",
              "       -0.54181356])"
            ]
          },
          "execution_count": 218,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_scaled[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Итак, данные готовы, тестируем модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшее значение C: 100.0\n",
            "ROC-AUC на тесте: 0.8280\n",
            "\n",
            "Результаты кросс-валидации:\n",
            "C=100.000: Средний ROC-AUC = 0.8497\n",
            "C=10.000: Средний ROC-AUC = 0.8496\n",
            "C=1.000: Средний ROC-AUC = 0.8492\n",
            "C=0.100: Средний ROC-AUC = 0.8480\n",
            "C=0.010: Средний ROC-AUC = 0.8457\n",
            "C=0.001: Средний ROC-AUC = 0.8412\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "# Создание пайплайна с нормализацией и моделью\n",
        "pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegressionCV(\n",
        "        Cs=[100, 10, 1, 0.1, 0.01, 0.001],  # Тестируемые значения C\n",
        "        cv=5,                   # Количество фолдов\n",
        "        scoring='roc_auc',      # Метрика для выбора C\n",
        "        solver='liblinear',     # Решатель для небольших данных\n",
        "        max_iter=1000,          # Увеличиваем число итераций\n",
        "        refit=True,             # Переобучить на всём трейне с лучшим C\n",
        "        random_state=42,\n",
        "        n_jobs=-1               # Использовать все ядра\n",
        "    )\n",
        ")\n",
        "\n",
        "# Обучение модели\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Извлечение обученной модели\n",
        "best_model = pipeline.named_steps['logisticregressioncv']\n",
        "\n",
        "# Лучшее значение C\n",
        "best_C = best_model.C_[0]\n",
        "print(f'Лучшее значение C: {best_C}')\n",
        "\n",
        "# Оценка на тестовой выборке\n",
        "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f'ROC-AUC на тесте: {test_roc_auc:.4f}')\n",
        "\n",
        "# Результаты кросс-валидации для каждого C\n",
        "print(\"\\nРезультаты кросс-валидации:\")\n",
        "for C, score in zip(best_model.Cs_, best_model.scores_[1].mean(axis=0)):\n",
        "    print(f\"C={C:.3f}: Средний ROC-AUC = {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mean_scores = best_model.scores_[1].mean(axis=0)\n",
        "plt.plot(best_model.Cs_, mean_scores, marker='o')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('ROC-AUC')\n",
        "plt.title('Зависимость ROC-AUC от C')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xHCLDmwqEEZL"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2Yv3uYtEEZO"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVahy6JKEEZQ"
      },
      "source": [
        "Выпишите какое лучшее качество и с какими параметрами вам удалось получить"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36729TOQEEZR"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlTeVy7fEEZR"
      },
      "source": [
        "## Применение градиентного бустинга (2 балла)\n",
        "\n",
        "Если вы хотите получить баллы за точный ответ, то стоит попробовать градиентный бустинг. Часто градиентный бустинг с параметрами по умолчанию даст вам 80% результата за 0% усилий.\n",
        "\n",
        "Мы будем использовать catboost, поэтому нам не надо кодировать категориальные признаки. Catboost сделает это сам (в .fit() надо передать cat_features=cat_cols). А численные признаки нормировать для моделей, основанных на деревьях не нужно.\n",
        "\n",
        "1) Разделите выборку на train/valid. Протестируйте catboost cо стандартными параметрами.\n",
        "\n",
        "2) Протестируйте разные занчения параметров количества деревьев и learning_rate'а и выберите лучшую по метрике ROC-AUC комбинацию.\n",
        "\n",
        "(Дополнительно) Есть некоторые сложности с тем, чтобы использовать CatBoostClassifier вместе с GridSearchCV, поэтому мы не просим использовать кроссвалидацию. Но можете попробовать)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fioxxlp-EEZS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf4Kjt96EEZU"
      },
      "source": [
        "Выпишите, какое лучшее качество и с какими параметрами вам удалось получить"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2d9GolXEEZV"
      },
      "source": [
        "ВАШ ОТВЕТ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDMXbvNZEEZV"
      },
      "source": [
        "# Предсказания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_P4wFNaEEZW",
        "outputId": "1fba5dfc-88e4-49e3-ed8a-afe21ae3325a"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-12-7d881febecc7>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-7d881febecc7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    best_model = # какая-то предыдущая модель\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "best_model = # какая-то предыдущая модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClientPeriod                                    0\n",
              "MonthlySpending                                 0\n",
              "TotalSpent                                      0\n",
              "Sex_Female                                      0\n",
              "Sex_Male                                        0\n",
              "IsSeniorCitizen_0                               0\n",
              "IsSeniorCitizen_1                               0\n",
              "HasPartner_No                                   0\n",
              "HasPartner_Yes                                  0\n",
              "HasChild_No                                     0\n",
              "HasChild_Yes                                    0\n",
              "HasPhoneService_No                              0\n",
              "HasPhoneService_Yes                             0\n",
              "HasMultiplePhoneNumbers_No                      0\n",
              "HasMultiplePhoneNumbers_No phone service        0\n",
              "HasMultiplePhoneNumbers_Yes                     0\n",
              "HasInternetService_DSL                          0\n",
              "HasInternetService_Fiber optic                  0\n",
              "HasInternetService_No                           0\n",
              "HasOnlineSecurityService_No                     0\n",
              "HasOnlineSecurityService_No internet service    0\n",
              "HasOnlineSecurityService_Yes                    0\n",
              "HasOnlineBackup_No                              0\n",
              "HasOnlineBackup_No internet service             0\n",
              "HasOnlineBackup_Yes                             0\n",
              "HasDeviceProtection_No                          0\n",
              "HasDeviceProtection_No internet service         0\n",
              "HasDeviceProtection_Yes                         0\n",
              "HasTechSupportAccess_No                         0\n",
              "HasTechSupportAccess_No internet service        0\n",
              "HasTechSupportAccess_Yes                        0\n",
              "HasOnlineTV_No                                  0\n",
              "HasOnlineTV_No internet service                 0\n",
              "HasOnlineTV_Yes                                 0\n",
              "HasMovieSubscription_No                         0\n",
              "HasMovieSubscription_No internet service        0\n",
              "HasMovieSubscription_Yes                        0\n",
              "HasContractPhone_Month-to-month                 0\n",
              "HasContractPhone_One year                       0\n",
              "HasContractPhone_Two year                       0\n",
              "IsBillingPaperless_No                           0\n",
              "IsBillingPaperless_Yes                          0\n",
              "PaymentMethod_Bank transfer (automatic)         0\n",
              "PaymentMethod_Credit card (automatic)           0\n",
              "PaymentMethod_Electronic check                  0\n",
              "PaymentMethod_Mailed check                      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 221,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l_test.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfSufx0CEEZZ"
      },
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "# X_test = pd.read_csv('./test.csv')\n",
        "# submission = pd.read_csv('./submission.csv')\n",
        "\n",
        "# Получение вероятностей для класса 1 (вторая колонка [:, 1])\n",
        "probabilities = best_model.predict_proba(l_test)[:, 1]  # Если используется l_test, замените X_test на l_test\n",
        "\n",
        "for i in range(len(submission['Churn'])):\n",
        "    submission['Churn'][i] = round(probabilities[i])\n",
        "# Запись предсказаний в submission-файл\n",
        "# submission['Churn'] = round(probabilities)\n",
        "\n",
        "# Сохранение результатов\n",
        "submission.to_csv('./my_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzGirrp5l2I-"
      },
      "source": [
        "Лучшее решение отправьте в Stepik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoNce9Yu0OM5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
