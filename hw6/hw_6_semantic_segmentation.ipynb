{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbTeDP5Tbou"
      },
      "source": [
        "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
        "\n",
        "<h3 style=\"text-align: center;\"><b>Домашнее задание. Сегментация изображений</b></h3>\n",
        "\n",
        "\n",
        "В этом задании вам предстоит решить задачу сегментации медицинских снимков. Домашнее задание можно разделить на следующие части:\n",
        "\n",
        "* Построй свой первый бейзлайн! [6]\n",
        "  * BCE Loss [2]\n",
        "  * SegNet [2]\n",
        "  * Train [1]\n",
        "  * Test [1]\n",
        "* Мир других лоссов! [2]\n",
        "  * Dice Loss [1]\n",
        "  * Focal Loss [1]\n",
        "  * BONUS: лосс из статьи [5]\n",
        "* Новая модель! [2]\n",
        "  * UNet [2]\n",
        "\n",
        "\n",
        "**Максимальный балл:** 10 баллов.\n",
        "\n",
        "Также для студентов желающих еще более углубиться в задачу предлагается решить бонусное задание, которое даст дополнительные 5 баллов. BONUS задание необязательное.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJM7MHbsmaFC"
      },
      "source": [
        "# Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2QCMgENTbox"
      },
      "source": [
        "1. Для начала мы скачаем датасет: [ADDI project](https://www.fc.up.pt/addi/ph2%20database.html).\n",
        "2. Разархивируем .rar файл.\n",
        "3. Обратите внимание, что папка  `PH2 Dataset images` должна лежать там же где и ipynb notebook.\n",
        "\n",
        "Это фотографии двух типов **поражений кожи:** меланома и родинки.\n",
        "В данном задании мы не будем заниматься их классификацией, а будем **сегментировать** их."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc97-tI-MulP",
        "outputId": "deb89b9c-a3a0-403e-bca0-6e8bdfc782ac"
      },
      "outputs": [],
      "source": [
        "!gdown 1T_RPkPP0jeWwK8L1UrmBw8V30eD7v6Ql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aax7-y3GUJ-E"
      },
      "outputs": [],
      "source": [
        "get_ipython().system_raw(\"unrar x PH2Dataset.rar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7feNwXOTboz"
      },
      "source": [
        "Стуктура датасета у нас следующая:\n",
        "\n",
        "    IMD_002/\n",
        "        IMD002_Dermoscopic_Image/\n",
        "            IMD002.bmp\n",
        "        IMD002_lesion/\n",
        "            IMD002_lesion.bmp\n",
        "        IMD002_roi/\n",
        "            ...\n",
        "    IMD_003/\n",
        "        ...\n",
        "        ...\n",
        "\n",
        " Здесь `X.bmp` — изображение, которое нужно сегментировать, `X_lesion.bmp` — результат сегментации.\n",
        "\n",
        "Для загрузки датасета можно использовать skimage: [`skimage.io.imread()`](https://scikit-image.org/docs/dev/api/skimage.io.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJiSRaM3Tbo1"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "lesions = []\n",
        "from skimage.io import imread\n",
        "import os\n",
        "root = 'PH2Dataset'\n",
        "\n",
        "for root, dirs, files in os.walk(os.path.join(root, 'PH2 Dataset images')):\n",
        "    if root.endswith('_Dermoscopic_Image'):\n",
        "        images.append(imread(os.path.join(root, files[0])))\n",
        "    if root.endswith('_lesion'):\n",
        "        lesions.append(imread(os.path.join(root, files[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_twp3KFiTbpC"
      },
      "source": [
        "Изображения имеют разные размеры. Давайте изменим их размер на $256\\times256 $ пикселей. Для изменения размера изображений можно использовать [`skimage.transform.resize()`](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.resize).\n",
        "Эта функция также автоматически нормализует изображения в диапазоне $[0,1]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODC0aMJBTbpH"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "size = (256, 256)\n",
        "X = [resize(x, size, mode='constant', anti_aliasing=True,) for x in images]\n",
        "Y = [resize(y, size, mode='constant', anti_aliasing=False) > 0.5 for y in lesions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m5zleU8TbpO",
        "outputId": "6c2987b6-25cc-4498-d34e-a8edf931dcf2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X = np.array(X, np.float32)\n",
        "Y = np.array(Y, np.float32)\n",
        "print(f'Loaded {len(X)} images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RL-7C-fTbpV"
      },
      "source": [
        "Чтобы убедиться, что все корректно, мы нарисуем несколько изображений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "7iS3oK0hTbpX",
        "outputId": "3b29d276-2d58-46c4-f990-4555abbf9737"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 6, i+1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(X[i])\n",
        "\n",
        "    plt.subplot(2, 6, i+7)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(Y[i])\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKFGOpePTbpd"
      },
      "source": [
        "Разделим наши 200 картинок на 100/50/50\n",
        " для обучения, валидации и теста соответственно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imqjeizbTbpe"
      },
      "outputs": [],
      "source": [
        "ix = np.random.choice(len(X), len(X), False)\n",
        "tr, val, ts = np.split(ix, [100, 150])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-uxCdAKTbpi",
        "outputId": "638dd1ff-9b95-438a-ace0-145224885065"
      },
      "outputs": [],
      "source": [
        "print(len(tr), len(val), len(ts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dusa9kAhTbpm"
      },
      "source": [
        "## PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, lesions, transform=None):\n",
        "        self.images = images\n",
        "        self.lesions = lesions\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        lesion = self.lesions[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            lesion = self.transform(lesion)\n",
        "\n",
        "        return image, lesion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHYLt5eqTbpp"
      },
      "outputs": [],
      "source": [
        "batch_size = 25\n",
        "\n",
        "train_dataset = SegmentationDataset(X[tr], Y[tr])\n",
        "val_dataset = SegmentationDataset(X[val], Y[val])\n",
        "test_dataset = SegmentationDataset(X[ts], Y[ts])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Проверим, что наш DataLoader правильно загружает данные\n",
        "for images, labels in train_dataloader:\n",
        "    print(f\"Batch of images shape: {images.shape}\")\n",
        "    print(f\"Batch of labels shape: {labels.shape}\")\n",
        "    break  # Выводим только первый батч для проверки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3kX6NaSTbpy",
        "outputId": "cd007b0d-1ab0-4fd5-a717-91c3c4a8b97d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6wwZLbShECa"
      },
      "source": [
        "# Метрика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snjDAp0zFyQD"
      },
      "source": [
        "## IoU (intersection over union)\n",
        "\n",
        "В данном разделе предлагается использовать следующую метрику для оценки качества:\n",
        "\n",
        "$I o U=\\frac{\\text {target } \\cap \\text { prediction }}{\\text {target } \\cup{prediction }}$\n",
        "\n",
        "Пересечение (A ∩ B) состоит из пикселей, найденных как в маске предсказания, так и в основной маске истины, тогда как объединение (A ∪ B) просто состоит из всех пикселей, найденных либо в маске предсказания, либо в целевой маске.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uVFPgA6iGtk"
      },
      "source": [
        "Что будет являться пересением и объединением в задаче сегментации?\n",
        "\n",
        "Давайте разберем следующий пример:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz3UlabmbwgB"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import JaccardIndex\n",
        "\n",
        "iou_score = JaccardIndex(threshold=0.5, task=\"binary\", average='none').to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgTPr4BY5yjN"
      },
      "source": [
        "# Построй свой первый бейзлайн!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2M9GxoN9O3n"
      },
      "source": [
        "Итак, загрузка файлов, код датасета и даталоадера написана за вас. Метрика IoU написана за вас! Вам остается написать лосс, модель и функции обучения и теста модели.\n",
        "\n",
        "* Построй свой первый бейзлайн! [6]\n",
        "  * BCE Loss [2]\n",
        "  * SegNet [2]\n",
        "  * Train [1]\n",
        "  * Test [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP7rWDfzoa54"
      },
      "source": [
        "## BCE Loss [2 балла]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEqpBjtrTbqC"
      },
      "source": [
        "Популярным лоссом для бинарной сегментации является *бинарная кросс-энтропия*, которая задается следующим образом:\n",
        "\n",
        "$$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right] \\space [1]$$\n",
        "\n",
        "где $y$ это  таргет желаемого результата и $\\hat y$ является выходом модели. $\\sigma$ - это [*логистическая* функция](https://en.wikipedia.org/wiki/Sigmoid_function), который преобразует действительное число $\\mathbb R$ в вероятность $[0,1]$.\n",
        "\n",
        "Однако эта потеря страдает от проблем численной нестабильности. Самое главное, что $\\lim_{x\\rightarrow0}\\log(x)=\\infty$ приводит к неустойчивости в процессе оптимизации. Рекомендуется посмотреть следующее [упрощение](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits). Эта функция эквивалентна первой и не так подвержена численной неустойчивости:\n",
        "\n",
        "$$\\mathcal L_{BCE} = \\hat y - y\\hat y + \\log\\left(1+\\exp(-\\hat y)\\right) \\space [2]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3ppoKDYb8G5"
      },
      "source": [
        "### Вывод численно стабильной формулы BCE лосса [1 балл]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INKekMEgQVXc"
      },
      "source": [
        "Выведите из формулы [1] формулу [2]:\n",
        "\n",
        "$$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right] \\space [1]$$\n",
        "\n",
        "$$\\mathcal L_{BCE} = \\hat y - y\\hat y + \\log\\left(1+\\exp(-\\hat y)\\right) \\space [2]$$\n",
        "\n",
        "Не забываем, что здесь $\\hat y_i$ - это логиты сети, не вероятности и не лейблы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwTSreiVcsx2"
      },
      "source": [
        "Ответ: $$-\\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right] = -[y\\log(\\frac{1}{1+e^{-\\hat y}}) + (1-y)\\log(1-\\frac{1}{1+e^{-\\hat y}})] = -[-y\\log(1+e^{-\\hat y}) + (1-y)\\log(\\frac{e^{-\\hat y}}{1+e^{-\\hat y}})] = -[-y\\log(1+e^{-\\hat y}) + (1-y)(-\\hat y - \\log(1+e^{-\\hat y}))] = -[-y\\log(1+e^{-\\hat y}) - \\hat y + y \\hat y - \\log(1+e^{-\\hat y}) + y\\log(1+e^{\\hat y})] = \\boxed{\\hat y - y\\hat y + \\log(1+e^{-\\hat y})}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK0x-jySc2AX"
      },
      "source": [
        "### Реализуйте в коде оба варианта лосса [1 балл]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQVpEB609FfW"
      },
      "source": [
        "Реализуйте следующие функции:\n",
        "\n",
        "*   `bce_true()` - честная прямая реализация лосса с формулой $$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right].$$\n",
        "*   `bce_loss()` - реализация формулы, которую мы вывели $$\\mathcal L_{BCE} = \\hat y - y\\hat y + \\log\\left(1+\\exp(-\\hat y)\\right).$$\n",
        "\n",
        "И сравните результаты функций с реализацией Pytorch:\n",
        "*   `bce_torch()`\n",
        "*   `bce_torch_with_logits()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bce_torch = torch.nn.BCELoss(reduction='mean')\n",
        "bce_torch_with_logits = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "# Проверка того, что наш лосс работает корректно\n",
        "y_pred = torch.randn(3, 2, requires_grad=True)\n",
        "y_true = torch.rand(3, 2)\n",
        "\n",
        "# Сравнение результатов\n",
        "print(f'BCE loss from scratch bce_loss = {bce_loss(y_pred, y_true)}')\n",
        "print(f'BCE loss честно посчитанный = {bce_true(y_pred, y_true)}')\n",
        "print(f'BCE loss from torch bce_torch = {bce_torch(torch.sigmoid(y_pred), y_true)}')\n",
        "print(f'BCE loss from torch with logits bce_torch = {bce_torch_with_logits(y_pred, y_true)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "558fBQtz9oxJ"
      },
      "source": [
        "Проверим корректность работы на простом примере"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHDf_SfB8o2i",
        "outputId": "74d58e2e-fda3-4753-f055-21b64241e20a"
      },
      "outputs": [],
      "source": [
        "y_pred = torch.randn(3, 2, requires_grad=False)\n",
        "y_true = torch.rand(3, 2, requires_grad=False)\n",
        "\n",
        "print(f'BCE loss from scratch bce_loss = {bce_loss(y_pred, y_true)}')\n",
        "print(f'BCE loss честно посчитанный = {bce_true(y_pred, y_true)}')\n",
        "print(f'BCE loss from torch bce_torch = {bce_torch(torch.sigmoid(y_pred), y_true)}')\n",
        "print(f'BCE loss from torch with logits bce_torch = {bce_torch_with_logits(y_pred, y_true)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WliQqbt_OCQW"
      },
      "source": [
        "Инструкции `assert` в Python — это булевы выражения, которые проверяют, является ли условие истинным (`True`). Внизу в коде мы проверяем функция `bce_loss()` выдает тот же результат, что и функция из Pytorch или нет. Если равенства не будет, что будет означать, что результаты функций не совпадают, а значит вы неправильно реализовали фукнцию `bce_loss()`, `assert` возвратит ошибку.\n",
        "\n",
        "Функция `numpy.isclose()` используется для сравнения двух чисел с учётом допустимой погрешности. Она особенно полезна при работе с числами с плавающей точкой, где точное сравнение может быть проблематичным из-за ограничений представления таких чисел в компьютере.\n",
        "\n",
        "Как она работает?\n",
        "\n",
        "`numpy.isclose(a, b, rtol=1e-05, atol=1e-08) `принимает два числа (`a` и `b`) и сравнивает их, учитывая относительную и абсолютную погрешность. Если разница между двумя числами меньше заданного порога, функция возвращает `True`, иначе — `False`.\n",
        "\n",
        "Параметры:\n",
        "\n",
        "    rtol: Относительная погрешность (по умолчанию 1e-05). Используется для определения разницы относительно большего значения.\n",
        "    atol: Абсолютная погрешность (по умолчанию 1e-08). Определяет минимальную разницу, которую следует учитывать.\n",
        "\n",
        "Мы будем использовать `assert` и `numpy.isclose()` для проверки корректности нашего кода."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGDkjpsq0Vf-"
      },
      "outputs": [],
      "source": [
        "# Проверяем, что лосс из Pytorch совпадает с нашей реализацией\n",
        "assert np.isclose(bce_loss(y_pred, y_true).item(), bce_torch(torch.sigmoid(y_pred), y_true).item())\n",
        "assert np.isclose(bce_loss(y_pred, y_true).item(), bce_torch_with_logits(y_pred, y_true).item())\n",
        "assert np.isclose(bce_true(y_pred, y_true).item(), bce_torch(torch.sigmoid(y_pred), y_true).item())\n",
        "assert np.isclose(bce_true(y_pred, y_true).item(), bce_torch_with_logits(y_pred, y_true).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s30-ThuV96bo"
      },
      "source": [
        "Давайте теперь посчитаем на простом примере, но с теми же размерностями, что и в датасете"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1rP3MzN9_GS",
        "outputId": "fd54a81a-a754-4d76-e0aa-9108cde2fe39"
      },
      "outputs": [],
      "source": [
        "y_pred = torch.randn((2, 1, 3, 3), requires_grad=False)\n",
        "y_true = torch.randint(0, 2, (2, 1, 3, 3))\n",
        "\n",
        "print(f'BCE loss from scratch bce_loss = {bce_loss(y_pred, y_true)}')\n",
        "print(f'BCE loss честно посчитанный = {bce_true(y_pred, y_true)}')\n",
        "print(f'BCE loss from torch bce_torch = {bce_torch(torch.sigmoid(y_pred), y_true.to(torch.float))}')\n",
        "print(f'BCE loss from torch with logits bce_torch = {bce_torch_with_logits(y_pred, y_true.to(torch.float))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsOhR3_Kd3dw"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(bce_loss(y_pred, y_true), bce_torch(torch.sigmoid(y_pred), y_true.to(torch.float)))\n",
        "assert np.isclose(bce_loss(y_pred, y_true), bce_torch_with_logits(y_pred, y_true.to(torch.float)))\n",
        "assert np.isclose(bce_true(y_pred, y_true), bce_torch(torch.sigmoid(y_pred), y_true.to(torch.float)))\n",
        "assert np.isclose(bce_true(y_pred, y_true), bce_torch_with_logits(y_pred, y_true.to(torch.float)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnYUlhdIft29"
      },
      "source": [
        "Давайте посчитаем на реальных логитах и сегментационной маске:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M_Hbo4cf1nE"
      },
      "outputs": [],
      "source": [
        "!gdown --folder 1EX0RW1TRQVkLmR1h6miCQqyhYPFyg28M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdzjeeFhgzoI"
      },
      "outputs": [],
      "source": [
        "path_to_dummy_samples = '/content/for_asserts'\n",
        "dummpy_sample = {'logits': torch.load(f'{path_to_dummy_samples}/logits.pt'),\n",
        "                 'labels': torch.load(f'{path_to_dummy_samples}/labels.pt')}\n",
        "dummpy_sample['labels'] = dummpy_sample['labels'].to(device)\n",
        "dummpy_sample['logits'] = dummpy_sample['logits'].to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gopwq6Q-hY4j"
      },
      "source": [
        "Проверяем на данном примере:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYhsBjzshBmr"
      },
      "outputs": [],
      "source": [
        "bce_loss_score = bce_loss(dummpy_sample['logits'].cpu(), dummpy_sample['labels'].cpu())\n",
        "bce_true_score = bce_true(dummpy_sample['logits'].cpu(), dummpy_sample['labels'].cpu())\n",
        "bce_torch_score = bce_torch(torch.sigmoid(dummpy_sample['logits'].cpu()), dummpy_sample['labels'].cpu().float())\n",
        "bce_torch_with_logits_score = bce_torch_with_logits(dummpy_sample['logits'].cpu(), dummpy_sample['labels'].cpu().float())\n",
        "assert np.isclose(bce_loss_score, bce_torch_score)\n",
        "assert np.isclose(bce_loss_score, bce_torch_with_logits_score)\n",
        "assert np.isclose(bce_true_score, bce_torch_score)\n",
        "assert np.isclose(bce_true_score, bce_torch_with_logits_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7iTtl0q_5JG"
      },
      "source": [
        "## SegNet [2 балла]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn249DoITbp3"
      },
      "source": [
        "Ваше задание здесь состоит в том, чтобы реализовать SegNet архитектуру.\n",
        "\n",
        "* Badrinarayanan, V., Kendall, A., & Cipolla, R. (2015). [SegNet: A deep convolutional\n",
        "encoder-decoder architecture for image segmentation](https://arxiv.org/pdf/1511.00561.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2siJZ4mW6Qr"
      },
      "source": [
        "Внимательно посмотрите из чего состоит модель и для чего выбраны те или иные блоки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-jqIVk2Tbp5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from time import time\n",
        "\n",
        "from matplotlib import rcParams\n",
        "rcParams['figure.figsize'] = (15,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwJQvMUaC77M"
      },
      "source": [
        "Хорошие ресурсы по SegNet архитектуре:\n",
        "1. https://medium.com/@nikdenof/segnet-from-scratch-using-pytorch-3fe9b4527239\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDsSrmbeTbp9"
      },
      "outputs": [],
      "source": [
        "class SegNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # VGG-16 architecture\n",
        "        # TODO\n",
        "\n",
        "        # bottleneck\n",
        "        # TODO\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        # TODO\n",
        "\n",
        "        # bottleneck\n",
        "        # TODO\n",
        "\n",
        "        # decoder\n",
        "        # TODO\n",
        "\n",
        "        return output # no activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVlUTAsiJHUW"
      },
      "outputs": [],
      "source": [
        "segnet_model = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4nnXmMbTbqJ"
      },
      "source": [
        "## Тренировка [1 балл]\n",
        "\n",
        "Напишите функцию для обучения модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4NuogMNL0UK"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ_UFglyTbqM"
      },
      "outputs": [],
      "source": [
        "def train(...):\n",
        "  # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiMR9mjKkZkI"
      },
      "source": [
        "Обучите модель **SegNet**. В качестве оптимайзера можно взять Adam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gfGgM8MIciL"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "train(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfZLYP_wTbqU"
      },
      "source": [
        "## Инференс [1 балл]\n",
        "\n",
        "После обучения модели напишите фукнцию теста, воспользуйтесь лучшим чекпоинтом и протестируйте работу модели на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXsVK5blWJAn"
      },
      "outputs": [],
      "source": [
        "def test(...):\n",
        "  # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nA92sStIeqo"
      },
      "outputs": [],
      "source": [
        "test(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dad8uz258mtn"
      },
      "source": [
        "# Мир других лоссов!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jLURieDp1VN"
      },
      "source": [
        "## Дополнительные функции потерь [2 балла]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tNJA3AoTbrq"
      },
      "source": [
        "В данном разделе вам потребуется имплементировать две функции потерь: DICE и Focal loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09E6B1ceo5hc"
      },
      "source": [
        "### Dice Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnGqgb-Tbrt"
      },
      "source": [
        "**1. Dice coefficient:** Учитывая две маски $X$ и $Y$, общая метрика для измерения расстояния между этими двумя масками задается следующим образом:\n",
        "\n",
        "$$D(X,Y)=\\frac{2|X\\cap Y|}{|X|+|Y|}$$\n",
        "\n",
        "В терминах матрицы ошибок она будет считаться следующим образом:\n",
        "\n",
        "$$D(X,Y) = \\frac{2TP}{2TP + FP + FN}$$\n",
        "\n",
        "Эта функция не является дифференцируемой, но это необходимое свойство для градиентного спуска. В данном случае мы можем приблизить его с помощью:\n",
        "\n",
        "$$\\mathcal L_D(X,Y) = 1- D(X, Y)$$\n",
        "\n",
        "**Hints** (!):\n",
        "\n",
        "1. Не забудьте подумать о численной нестабильности, возникающей в математической формуле при ситуации, когда $\\frac{0}{0}$, т.е. вам нужно добавить очень маленькое число, например $\\epsilon = 1e^{-8}$, в обе части дроби при подсчете $D(X,Y)$:\n",
        "\n",
        "$$D(X,Y) = \\frac{2TP + ϵ}{2TP + FP + FN + ϵ}$$\n",
        "\n",
        "2. Dice метрика(!), не лосс, считается похожим образом как IoU:\n",
        "\n",
        "    2.1. На вход вам приходят logits, т.е. значения от $-∞$ до $∞$. Их переводим в вероятности от 0 до 1 при помощи функции Sigmoid.\n",
        "\n",
        "    2.2. Фиксируем порог, например threshold=0.5, и всему что ниже порога ставим значение 0, всему что выше 1. Получаем предсказанную маску из 0 и 1.\n",
        "\n",
        "    2.3. Считаем TP, FP, FN\n",
        "\n",
        "    2.4. Считаем DICE метрику по формуле\n",
        "\n",
        "Вы можете прописать для себя функцию `dice_score()` и сравнить с результатами работы функции из библиотеки `torchmetrics`.\n",
        "\n",
        "3. Но с метрикой есть проблема, что она не дифференцируема, и если вы захотите просто взять и прописать `dice_loss` = 1 - `dice_score`, Pytorch поругается на вас и скажет, что это недифференцируемая метрика. Чтобы посчитать dice_loss делаем следующие шаги:\n",
        "\n",
        "    3.1. На вход вам приходят logits, т.е. значения от $-∞$ до $∞$. Их переводим в вероятности от 0 до 1 при помощи функции Sigmoid.\n",
        "\n",
        "    3.2. Здесь нам уже не нужно фиксировать порог, мы просто работаем с вероятностями. Значения вероятностей дифференцируемы и через них будут протекать градиенты.\n",
        "\n",
        "    3.3. Считаем TP, FP, FN также как и в Dice метрике, только вместо маски, подаем вероятности.\n",
        "\n",
        "    3.4. Считаем DICE метрику по формуле\n",
        "\n",
        "    3.5. Считаем лосс как Loss = 1 - DICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIt43mkwIgsS"
      },
      "source": [
        "Итак, давайте сначала пропишем dice_score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRr875R0BkRa"
      },
      "outputs": [],
      "source": [
        "def dice_score(logits: torch.Tensor, labels: torch.Tensor, threshold: float = 0.5):\n",
        "    '''\n",
        "    Это именно метрика, не лосс.\n",
        "    '''\n",
        "    # TODO\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqOe10BcIl0Z"
      },
      "source": [
        "Проверим на корректность функцию dice_score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bfp5UCm4Rtk",
        "outputId": "d7950317-ec27-4929-eb85-ebe0036ae0be"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.segmentation import DiceScore\n",
        "\n",
        "dice = DiceScore(num_classes=1, average='micro').to(device)\n",
        "dice(dummpy_sample['logits'].sigmoid(), dummpy_sample['labels'].to(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwz-kUo-zuUu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "если вы используете версию библиотеки 0.11.4, то можно взять torchmetrics.classification.Dice():\n",
        "\n",
        "from torchmetrics.classification import Dice\n",
        "\n",
        "dice = Dice(average='micro').to(device)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9AAYG7IIlWK"
      },
      "outputs": [],
      "source": [
        "assert dice(dummpy_sample['logits'].sigmoid(), dummpy_sample['labels'].to(int)) == dice_score(dummpy_sample['logits'], dummpy_sample['labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5dOJMM7B8CM"
      },
      "source": [
        "Давайте теперь пропишем лосс и воспользуемся библиотекой `segmentation-models-pytorch`, чтобы убедиться в корректности нашей функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "681zcHDDB7Rw"
      },
      "outputs": [],
      "source": [
        "def dice_loss(logits: torch.Tensor, labels: torch.Tensor):\n",
        "\n",
        "    '''\n",
        "    Это лосс.\n",
        "    '''\n",
        "    # TODO\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJSxrsngI1x7"
      },
      "source": [
        "Проверка на корректность:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmn6wTdqzuUx"
      },
      "outputs": [],
      "source": [
        "# проверьте, что у вас установлена библиотека\n",
        "#!pip install segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jb9-KxrI39U"
      },
      "outputs": [],
      "source": [
        "from segmentation_models_pytorch.losses import DiceLoss\n",
        "dice_loss_torch = DiceLoss(mode='binary')\n",
        "dice_loss_torch(dummpy_sample['logits'], dummpy_sample['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ill9aLhI600"
      },
      "outputs": [],
      "source": [
        "assert dice_loss_torch(dummpy_sample['logits'], dummpy_sample['labels'].to(int)) == dice_loss(dummpy_sample['logits'], dummpy_sample['labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec2d-VKSqEcZ"
      },
      "source": [
        "### Focal Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUGWQkVFTbsJ"
      },
      "source": [
        "[**2. Focal loss:**](https://arxiv.org/pdf/1708.02002.pdf)\n",
        "\n",
        "Окей, мы уже с вами умеем делать BCE loss:\n",
        "\n",
        "$$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right].$$\n",
        "\n",
        "Проблема с этой потерей заключается в том, что она имеет тенденцию приносить пользу классу **большинства** (фоновому) по отношению к классу **меньшинства** ( переднему). Поэтому обычно применяются весовые коэффициенты к каждому классу:\n",
        "\n",
        "$$\\mathcal L_{wBCE}(y, \\hat y) = -\\sum_i \\alpha_i\\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right].$$\n",
        "\n",
        "Традиционно вес $\\alpha_i$ определяется как обратная частота класса этого пикселя $i$, так что наблюдения миноритарного класса весят больше по отношению к классу большинства.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XK4bp5NpRlN"
      },
      "source": [
        "Из оригинальной статьи по [Focal Loss](https://arxiv.org/pdf/1708.02002.pdf):\n",
        "\n",
        "$$p_t = \\sigma(\\hat y_i)y_i + (1 - \\sigma(\\hat y_i)) (1-y_i)$$\n",
        "\n",
        "$$\\mathcal L_{focal}(y, \\hat y) = (1 - p_t)^{\\gamma} \\mathcal L_{BCE}(y_i, \\hat y_i).$$\n",
        "\n",
        "$$\\mathcal L_{focal}(y, \\hat y) = -\\sum_i (1 - p_t)^{\\gamma} \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right].$$\n",
        "\n",
        "$$\\mathcal L_{focal}(y, \\hat y) = -\\sum_i (1 - (\\sigma(\\hat y_i)y_i + (1 - \\sigma(\\hat y_i)) (1-y_i)))^{\\gamma} \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right].$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLogsetCTbsK"
      },
      "outputs": [],
      "source": [
        "def focal_loss(y_real, y_pred, eps = 1e-8, gamma = 2):\n",
        "    # TODO\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVTSDGuqI4HI"
      },
      "source": [
        "Проверка корректности функции:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PuR0v6jjq3J"
      },
      "outputs": [],
      "source": [
        "from torchvision.ops import sigmoid_focal_loss\n",
        "sigmoid_focal_loss(dummpy_sample['logits'], dummpy_sample['labels'], alpha=-1, gamma=2, reduction='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duvpJMJ28g3b"
      },
      "outputs": [],
      "source": [
        "assert sigmoid_focal_loss(dummpy_sample['logits'], dummpy_sample['labels'], alpha=-1, gamma=2, reduction='sum') == focal_loss(dummpy_sample['labels'], dummpy_sample['logits'], gamma=2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CReAQZr7TbsZ"
      },
      "source": [
        "## [BONUS] Мир сегментационных лоссов [5 баллов]\n",
        "\n",
        "В данном блоке предлагаем вам написать одну функцию потерь самостоятельно. Для этого необходимо прочитать статью и имплементировать ее, и провести численное сравнение с предыдущими функциями.\n",
        "\n",
        "* [Physiological Inspired Deep Neural Networks for Emotion Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472816&tag=1)\". IEEE Access, 6, 53930-53943.\n",
        "\n",
        "* [Boundary loss for highly unbalanced segmentation](https://arxiv.org/abs/1812.07032)\n",
        "\n",
        "* [Tversky loss function for image segmentation using 3D fully convolutional deep networks](https://arxiv.org/abs/1706.05721)\n",
        "\n",
        "* [Correlation Maximized Structural Similarity Loss for Semantic Segmentation](https://arxiv.org/abs/1910.08711)\n",
        "\n",
        "* [Topology-Preserving Deep Image Segmentation](https://papers.nips.cc/paper/8803-topology-preserving-deep-image-segmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwFw541ZVInP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naihust-AtrW"
      },
      "source": [
        "## Обучите SegNet на новых лоссах"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsb79GHfA4i-"
      },
      "source": [
        "**Задание**: обучите SegNet на новых лоссах и сравните все три лосса:\n",
        "*   При каком лоссе модель сходится быстрее?\n",
        "*   При каком лоссе модель выдает наилучшую метрику?\n",
        "\n",
        "Напишите развернутый ответ на вопросы.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP9YzaqbA16O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWpyOqvVAClS"
      },
      "source": [
        "# Новая модель!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU5KGWXaTbso"
      },
      "source": [
        "## U-Net [2 балла]\n",
        "\n",
        "[**U-Net**](https://arxiv.org/abs/1505.04597) — это архитектура нейронной сети, которая получает изображение и выводит его. Первоначально он был задуман для семантической сегментации (как мы ее будем использовать), но он настолько успешен, что с тех пор используется в других контекстах. Получая на вход медицинское изображение, он выведет изображение в оттенках серого, где интенсивность каждого пикселя зависит от вероятности того, что этот пиксель принадлежит интересующей нас области."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxrujK1gTbsp"
      },
      "source": [
        "У нас в архитектуре все так же существует энкодер и декодер, как в **SegNet**, но отличительной особеностью данной модели являются *skip-conenctions*, соединяющие части декодера и энкодера. То есть для того чтобы передать на вход декодера тензор, мы конкатенируем симметричный выход с энкодера и выход предыдущего слоя декодера.\n",
        "\n",
        "* Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. \"[U-Net: Convolutional networks for biomedical image segmentation.](https://arxiv.org/pdf/1505.04597.pdf)\" International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xITaxuonISEM"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAbpSJnZHxjO"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_class=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  TODO\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15GA_43BTbtI"
      },
      "outputs": [],
      "source": [
        "unet_model = UNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASlWq-DjAFJR"
      },
      "source": [
        "## Обучите UNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXdmmcdECA7v"
      },
      "source": [
        "Задание: обучите UNet на всех трех лоссах: BCE, Dice, Focal и сравните результаты с SegNet:\n",
        "*   Какая модель дает лучшие значения по метрике?\n",
        "*   Какая модель дает лучшие значения по лоссам?\n",
        "*   Какая модель обучается быстрее?\n",
        "*   Сравните визуально результаты SegNet и UNet.\n",
        "\n",
        "Напишите развернутый ответ на вопросы.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GJM7MHbsmaFC",
        "ec2d-VKSqEcZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
